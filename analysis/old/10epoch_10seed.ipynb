{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting page 2\n",
            "Getting page 3\n",
            "Getting page 4\n",
            "Getting page 5\n",
            "Getting page 6\n",
            "Getting page 7\n",
            "Getting page 8\n",
            "6664\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import datetime\n",
        "import pytz\n",
        "\n",
        "\n",
        "url = \"https://logs.betterstack.com/api/v1/query\"\n",
        "headers = {\n",
        "    \"Authorization\": \"Bearer 2oqgnLmr2d6QaNyEzS4FCv96\",\n",
        "}\n",
        "\n",
        "def get_data(params):\n",
        "    i = 2\n",
        "    params = {**params, \"batch\": 1000}\n",
        "    response = requests.get(url, headers=headers, params=params).json()\n",
        "    # add pagination\n",
        "    ret = response['data']\n",
        "    while response['pagination']['next'] and response['data']:\n",
        "        next_url = response['pagination']['next']\n",
        "        print('Getting page', i)\n",
        "        response = requests.get(next_url, headers=headers).json()\n",
        "        ret.extend(response['data'])\n",
        "        i += 1\n",
        "    return ret\n",
        "\n",
        "# 2024-02-14T11:49:58.747138+00:00\n",
        "# data = get_data({\"from\": \"2022-07-19T13:32:56+00:00\", \"to\": \"2025-07-19T13:32:56+00:00\"})\n",
        "\n",
        "\n",
        "data = get_data({\"from\": datetime.datetime(2024, 2, 14, 6, 49, 0, tzinfo=pytz.timezone('EST')).isoformat(), \n",
        "                 \"to\": datetime.datetime(2024, 2, 15, 11, 59, 0, tzinfo=pytz.timezone('EST')).isoformat()})\n",
        "\n",
        "print(len(data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "finished = []\n",
        "for d in data:\n",
        "    if 'Finished' in d['message'] and 'job!' in d['message']:\n",
        "        finished.append(int(d['message'].split(' ')[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2045"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(finished)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dt': '2024-02-14 11:49:58.747138',\n",
              " '_dt': '1707911398747138',\n",
              " '_insert_index': 134000010,\n",
              " 'json': '{\"context\":{\"runtime\":{\"file\":\"gemini.py\",\"function\":\"main\",\"line\":324,\"logger_name\":\"__main__\",\"thread_id\":140404180763008,\"thread_name\":\"MainThread\"},\"system\":{\"pid\":83,\"process_name\":\"MainProcess\"}},\"dt\":\"2024-02-14T11:49:58.747138+00:00\",\"extra\":{},\"filename\":\"gemini.py\",\"level\":\"info\",\"message\":\"START:24, END:48\",\"severity\":2}',\n",
              " '_app': 'reward_learning',\n",
              " '_source_id': '682629',\n",
              " 'level': 'info',\n",
              " 'message': 'START:24, END:48'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6664"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed:  [182, 170, 732]\n",
            "Number Results:  3819\n",
            "Finished: 2045\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "fin = []\n",
        "failed = []\n",
        "results = {}\n",
        "for i in data:\n",
        "    if 'Finished' in i['message']:\n",
        "        try:\n",
        "            fin.append(int(i['message'].split(' ')[1]))\n",
        "        except ValueError:\n",
        "            # print(i['message'])\n",
        "            continue\n",
        "    elif 'Failed' in i['message']:\n",
        "        try:\n",
        "            failed.append(int(i[\"message\"].split(\" \")[1]))\n",
        "        except ValueError:\n",
        "            print(i[\"message\"])\n",
        "    elif len([rm for rm in ['START', 'Config', 'Upload folder did not work'] if rm in i['message']]):\n",
        "        continue\n",
        "    else:\n",
        "        try:\n",
        "            results[i['message']] = json.loads(i['json'])['message_json']\n",
        "        except KeyError:\n",
        "            continue\n",
        "            # print(i['message'])\n",
        "print('Failed: ', failed)\n",
        "print('Number Results: ', len(results))\n",
        "print('Finished:', len(fin))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['reward',\n",
              " '1708004094.096381',\n",
              " 'rfbase',\n",
              " 'cotTrue',\n",
              " 'seed1',\n",
              " 'task',\n",
              " 'index=11',\n",
              " 'stage=0',\n",
              " 'iteration=0//logs/results/REWARDS',\n",
              " 'TASK11',\n",
              " 'REWbase',\n",
              " 'N48',\n",
              " 'B16',\n",
              " 'OPT0.9::']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keys = list(results.keys())\n",
        "\n",
        "keys[0].split('_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Callable, NewType\n",
        "import numpy.typing as npt\n",
        "import numpy as np\n",
        "\n",
        "RewardFun = Callable[[npt.NDArray, int], float]  # RewardFun(feature, state) -> r\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Task:\n",
        "    command: str\n",
        "    base: RewardFun\n",
        "    human: RewardFun\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "types of tasks:\n",
        "1) take tail of one feature distribution\n",
        "2) take lower and upper bound of one feature distribution\n",
        "3) combine two feature distributions\n",
        "4) use latent label that requires inference (previously impoverished, now impoverished, most at risk (mothers previously suffering from miscarriage or complications))\n",
        " \n",
        "These categories can then vary  by weight: focus slightly more, focus heavily, focus solely on\n",
        " \n",
        "And do this for every feature. \n",
        " \n",
        "This is already 4 x 3 = 240 tasks.\n",
        " \n",
        " We can also add negatives (slightly defocus/disadvantage/deprioritize) to get 240 * 2 = 480 tasks.\n",
        " \n",
        "4) take tail of one feature distribution and combine with another feature distribution\n",
        "5) take lower and upper bound of one feature distribution and combine with another feature distribution,\n",
        "6) combine two feature distributions and combine with another feature distribution\n",
        "7) take tail of one feature distribution and combine with another feature distribution and combine with another feature distribution\n",
        "8) take lower and upper bound of one feature distribution and combine with another feature distribution and combine with another feature distribution\n",
        " \n",
        "\"\"\"\n",
        "# task_commands = [\n",
        "#     # 1) Take tail of one feature distribution\n",
        "#     \"Identify the upper 10% of beneficiaries by age distribution.\",\n",
        "#     \"Extract the highest income_bracket distribution tail, focusing on the top 5%.\",\n",
        "#     \"Select the tail end of the 'duration' distribution to analyze the longest calls made to beneficiaries.\",\n",
        "#     \"Find the tail of the 'g' distribution representing the most pregnancies.\",\n",
        "#     \"Retrieve the tail distribution for 'attempt_no' to see the most frequent call attempt numbers.\",\n",
        "#     # \" 2) Take lower and upper bound of one feature distribution\",\n",
        "#     \"Determine the lower and upper quartile for the age feature.\",\n",
        "#     \"Calculate the income_bracket bounds for the middle 50% of the population.\",\n",
        "#     \"Find the boundaries of the 'duration' feature where 90% of the calls lie within.\",\n",
        "#     \"Establish the lower and upper bounds of 'enrollment_gestation_age' for the central 80% of the data.\",\n",
        "#     \"Set the thresholds for the 'l' feature to identify the common range of live births.\",\n",
        "#     # \" 3) Combine two feature distributions\",\n",
        "#     \"Combine the distributions of 'age' and 'education' to identify the correlation between the beneficiary's age and their educational attainment.\",\n",
        "#     \"Create a joint distribution of 'income_bracket' and 'phone_owner' to explore the financial status against phone ownership.\",\n",
        "#     \"Merge the 'slot' and 'duration' distributions to see if certain call times correlate with longer message listening durations.\",\n",
        "#     \"Integrate the distributions of 'g' (gravidity) and 'p' (parity) to analyze pregnancy and viable gestational ages together.\",\n",
        "#     \"Combine 'language_name' with 'Technical_success' to assess if the success of calls varies with language preferences.\",\n",
        "#     # \" 4) Use latent label that requires inference (previously impoverished, now impoverished, most at risk)\",\n",
        "#     \"Infer financial improvement by comparing past and present 'income_bracket' to label beneficiaries as 'previously impoverished' or 'now impoverished'.\",\n",
        "#     \"Identify 'most at risk' mothers by selecting those with a history of 's' (stillbirths) or who had complications mentioned in 'education' notes.\",\n",
        "#     \"Filter for beneficiaries who moved from the lowest 'income_bracket' and are not in the lowest anymore to infer economic improvement.\",\n",
        "#     \"Apply inference rules to 'age' and 'p' to identify mothers at high risk due to age and number of past pregnancies.\",\n",
        "#     \"Cross-reference 'Technical_success' with repeat 'attempt_no' to infer technical challenges that could indicate 'at-risk' beneficiaries due to poor connectivity or other issues.\",\n",
        "# ]\n",
        "\n",
        "\n",
        "SLIGHTLY_MODIFIER = 0.5\n",
        "HEAVILY_MODIFIER = 1\n",
        "\n",
        "\n",
        "def if_(x: bool):\n",
        "    return 1.0 if x else 0.0\n",
        "\n",
        "\n",
        "# TODO: compare this with the diversity of the actual dataset. for each task, how many people in the dataset does this actually apply to?\n",
        "# 01/24/24 removed abortion, subtract by one most indices\n",
        "# 02/12/24 remove stillbirth and infer. stillbirth gets 0 reward, and infer is too hard\n",
        "task_commands = [\n",
        "    # 1) Take tail of one feature distribution\n",
        "    Task(\n",
        "        \"Focus slightly on the most elderly by age distribution.\",\n",
        "        lambda feature, state: state + SLIGHTLY_MODIFIER * feature[12 - 1],\n",
        "        lambda feature, state: state**2 + SLIGHTLY_MODIFIER * feature[12 - 1],\n",
        "    ),\n",
        "    Task(\n",
        "        \"The lowest income_bracket distribution tail is very important, focus heavily on the top 12.5%.\",\n",
        "        lambda feature, state: state + HEAVILY_MODIFIER * feature[37 - 1],\n",
        "        lambda feature, state: state**2 + HEAVILY_MODIFIER * feature[37 - 1],\n",
        "    ),\n",
        "    Task(\n",
        "        \"Select solely those who speak Hindi to analyze how this would affect the calls made to our beneficiaries.\",\n",
        "        lambda feature, state: state * if_(feature[13 - 1]),\n",
        "        lambda feature, state: state**2 * if_(feature[13 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Priortize slightly those who have had prior pregnancies.\",  # g feature\n",
        "        lambda feature, state: state + SLIGHTLY_MODIFIER * if_(feature[2]),\n",
        "        lambda feature, state: state**2 + SLIGHTLY_MODIFIER * if_(feature[2]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Heavily weight those who have had low education.\",  # education_1\n",
        "        lambda feature, state: state + HEAVILY_MODIFIER * if_(feature[17 - 1]),\n",
        "        lambda feature, state: state**2 + HEAVILY_MODIFIER * if_(feature[17 - 1]),\n",
        "    ),\n",
        "    # \" 2) Take lower and upper bound of one feature distribution\",\n",
        "    Task(\n",
        "        \"Focus only on both the young and elderly.\",  # education_1\n",
        "        lambda feature, state: state * if_(feature[12 - 1] or feature[8 - 1]),\n",
        "        lambda feature, state: state**2 * if_(feature[12 - 1] or feature[8 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Prefer slightly on the income_bracket bounds for the middle 40% of the population.\",  # income_bracker 3, 4, 5\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(feature[39 - 1] or feature[40 - 1] or feature[41 - 1]),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(feature[39 - 1] or feature[40 - 1] or feature[41 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Slightly favor those women who do not own their own phone\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[25 - 1] or feature[26 - 1]),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[25 - 1] or feature[26 - 1]),\n",
        "    ),\n",
        "    # \"Establish the lower and upper bounds of 'enrollment_gestation_age' for the central 80% of the data.\",\n",
        "    # \"Set the thresholds for the 'l' feature to identify the common range of live births.\",\n",
        "    # \" 3) Combine two feature distributions\",\n",
        "    Task(\n",
        "        \"Combine the distributions of 'age' and 'education' to heavily give precedence to low income impoverished youth.\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[8 - 1] and feature[17 - 1]),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[8 - 1] and feature[17 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Focus slightly on the joint distribution of 'income_bracket' and 'phone_owner' for those with high financial status but with no phone ownership.\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(\n",
        "            (feature[40 - 1] or feature[41 - 1])\n",
        "            and (feature[25 - 1] or feature[26 - 1])\n",
        "        ),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(\n",
        "            (feature[40 - 1] or feature[41 - 1])\n",
        "            and (feature[25 - 1] or feature[26 - 1])\n",
        "        ),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Advantage slightly those who prefer being called after 7PM 'slot' registered at an NGO.\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[32 - 1] and feature[33 - 1]),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[32 - 1] and feature[33 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Integrate the distributions of 'g' (gravidity) and 'l' (live) to concentrate heavily on mothers who have several pregnancies but not much success with birth\",\n",
        "        lambda feature, state: state\n",
        "        + HEAVILY_MODIFIER * if_(feature[2] > 1 and feature[5] == 0),\n",
        "        lambda feature, state: state**2\n",
        "        + HEAVILY_MODIFIER * if_(feature[2] > 1 and feature[5] == 0),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Slightly fixate on those Marathi-speakers with middle-aged folks.\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(feature[14 - 1] and (feature[10 - 1] or feature[11 - 1])),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(feature[14 - 1] and (feature[10 - 1] or feature[11 - 1])),\n",
        "    ),\n",
        "    # \" 4) Use latent label that requires inference (previously impoverished, now impoverished, most at risk)\",\n",
        "    # Task(\n",
        "    #     \"Infer disempowered mothers with little opportunity and focus heavily on them.\",  # mothers with low education, low income, and no phone ownership\n",
        "    #     lambda feature, state: state\n",
        "    #     + HEAVILY_MODIFIER\n",
        "    #     * if_(\n",
        "    #         feature[14-1]\n",
        "    #         and (feature[25-1] or feature[26-1])\n",
        "    #         and (feature[37-1] or feature[38-1]),\n",
        "    #         lambda feature, state: state**2\n",
        "    #         + SLIGHTLY_MODIFIER * if_(feature[14-1] and (feature[25-1] or feature[26-1])),\n",
        "    #     ),\n",
        "    #     lambda feature, state: state**2\n",
        "    #     + HEAVILY_MODIFIER\n",
        "    #     * if_(\n",
        "    #         feature[14-1]\n",
        "    #         and (feature[25-1] or feature[26-1])\n",
        "    #         and (feature[37-1] or feature[38-1]),\n",
        "    #         lambda feature, state: state**2\n",
        "    #         + SLIGHTLY_MODIFIER * if_(feature[14-1] and (feature[25-1] or feature[26-1])),\n",
        "    #     ),\n",
        "    # ),\n",
        "    # Task(\n",
        "    #     \"Identify 'most at risk' mothers by selecting those with a history of 's' (stillbirths) and have had little education and prefer them solely.\",\n",
        "    #     lambda feature, state: state * if_(feature[4] and (feature[17-1] or feature[18-1])),\n",
        "    #     lambda feature, state: (state**2)\n",
        "    #     * if_(feature[4] and (feature[17-1] or feature[18-1])),\n",
        "    # ),\n",
        "    Task(\n",
        "        \"Give slightly more attention for beneficiaries who likely work early in the morning and late at night.\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[27 - 1] or feature[29 - 1]),\n",
        "        lambda feature, state: (state**2)\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[27 - 1] or feature[29 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Apply inference rules to 'age' and 'p' to identify mothers at high risk due to age and number of past pregnancies and focus heavily on them.\",\n",
        "        lambda feature, state: state\n",
        "        + HEAVILY_MODIFIER * if_((feature[11 - 1] or feature[12 - 1]) and feature[3]),\n",
        "        lambda feature, state: (state**2)\n",
        "        + HEAVILY_MODIFIER * if_((feature[11 - 1] or feature[12 - 1]) and feature[3]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Infer technical challenges in reaching the phone that could indicate 'at-risk' beneficiaries and give preference slightly.\",  # this just means phone ownership or potentially low income, but requires inference.\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER * if_((feature[25 - 1] or feature[26 - 1]))\n",
        "        and feature[3],\n",
        "        lambda feature, state: (state**2)\n",
        "        + SLIGHTLY_MODIFIER * if_((feature[25 - 1] or feature[26 - 1]))\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * 0.2\n",
        "        * if_((feature[37 - 1] or feature[38 - 1])),  # slight weighting for low income\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "# TODO: state**2 == state since state \\in {0, 1}? potential answer: squaring the full output of the reward for shaped reward\n",
        "# now we wrap the shap\n",
        "def shaped_wrapper(reward_fun: RewardFun) -> RewardFun:\n",
        "    def shaped_reward(feature: npt.NDArray, state: int) -> float:\n",
        "        return reward_fun(feature, state) ** 2\n",
        "\n",
        "    return shaped_reward\n",
        "\n",
        "\n",
        "TASKS = []\n",
        "for command in task_commands:\n",
        "    command.human = shaped_wrapper(command.human)\n",
        "    TASKS.append(command)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "\n",
        "def get_user_defined_attrs(cls) -> list:\n",
        "    return [\n",
        "        attr\n",
        "        for attr in dir(cls)\n",
        "        if not callable(getattr(cls, attr)) and not attr.startswith(\"__\")\n",
        "    ]\n",
        "\n",
        "\n",
        "class BaseHyperParameters:\n",
        "    @classmethod\n",
        "    def get_product(cls):\n",
        "        return list(\n",
        "            product(*[getattr(cls, attr) for attr in get_user_defined_attrs(cls)])\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class HyperParameters(BaseHyperParameters):\n",
        "    # TODO figure out better way to sort attrs without having to add number in beginning, and tie this so there's never a bug with reading the variables below    \n",
        "    _1_arm_budget = [(48, 16), (21, 7)]\n",
        "    # _2_arm_budget = [(48, 16)]\n",
        "    _2_cot = [True, False]    \n",
        "    _3_seeds = list(range(17)) + [12, 13, 42]\n",
        "    _4_task_indices = range(len(TASKS))\n",
        "    _5_n_train_epochs = [1, 3, 5]\n",
        "    _6_llm_reward = [True, False]\n",
        "\n",
        "\n",
        "\n",
        "og_hparams = HyperParameters.get_product()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class HyperParameters:\n",
        "    # alphabetical\n",
        "    _1_llm_reward: str\n",
        "    _2_arm_budget: int\n",
        "    _3_cot: bool\n",
        "    _4_seeds: int\n",
        "    _5_task_indices: int\n",
        "    # _6_zero_shot: bool    \n",
        "    _stage: int\n",
        "    _iteration: int\n",
        "\n",
        "\n",
        "def get_vars(key):\n",
        "    try:\n",
        "        _, time, _, cot, seed, _, task, stage, iteration, _, reward_type, arms, budget, optin = key.split('_')\n",
        "    except ValueError as e:\n",
        "        print(key.split('_'))\n",
        "        raise e\n",
        "    cot = eval(cot[3:])\n",
        "    budget = int(budget[1:])\n",
        "    arms = int(arms[1:])\n",
        "    seed = int(seed[4:])\n",
        "    stage = int(stage.split('=')[1])\n",
        "    task = int(task.split('=')[1])\n",
        "    iteration = int(iteration.split('=')[1].split('//')[0])\n",
        "\n",
        "    return HyperParameters(reward_type, arms, cot, seed, task, stage, iteration)\n",
        "\n",
        "\n",
        "hparams = [get_vars(k) for k in keys]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1152\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3819"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(192 * 4 + 192 + 192)\n",
        "len(hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 48 budget results\n",
        "from collections import defaultdict\n",
        "res = defaultdict(list)\n",
        "for hparam, key in zip(hparams, keys):\n",
        "    if hparam._2_arm_budget == 48:\n",
        "        # print(key)\n",
        "        res[f\"nocall_{hparam._5_task_indices}\"].append(results[key][\"No Calls\"][\"val\"])\n",
        "        res[f\"random_{hparam._5_task_indices}\"].append(results[key][\"RandomDS\"][\"val\"])\n",
        "\n",
        "        ret = results[key]['PreFeRMAB']\n",
        "        k = f\"{hparam._1_llm_reward[3:]}_{hparam._5_task_indices}\"\n",
        "        # if k == 'REWbase_9':\n",
        "        # print(hparam)\n",
        "        if hparam._1_llm_reward != \"REWllm\" and hparam._3_cot:        \n",
        "            res[k].append(ret['val'])\n",
        "            continue\n",
        "\n",
        "        # ignore zero shot for now\n",
        "        if hparam._stage == 0 and hparam._iteration == 0:\n",
        "            if hparam._3_cot:\n",
        "                res['zeroshot_'+k].append(ret['val'])\n",
        "            else:\n",
        "                res['COT_zeroshot_'+k].append(ret['val'])\n",
        "        if hparam._stage == 1 and hparam._iteration == 1:\n",
        "            if hparam._3_cot:\n",
        "                res['COT_'+k].append(ret['val'])\n",
        "            else:\n",
        "                res[k].append(ret['val'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(res['COT_llm_12'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nocall_0 140.1 4.69\n",
            "random_0 155.91 3.72\n",
            "base_0 181.04 17.31\n",
            "human_0 183.89 20.51\n",
            "llm_0 173.38 23.14\n",
            "zeroshot_llm_0 171.97 16.54\n",
            "COT_zeroshot_llm_0 168.45 24.13\n",
            "COT_llm_0 176.89 21.23\n",
            "\n",
            "nocall_1 199.39 15.49\n",
            "random_1 215.2 14.78\n",
            "base_1 243.51 13.32\n",
            "human_1 253.46 9.76\n",
            "llm_1 225.52 31.5\n",
            "zeroshot_llm_1 230.22 27.87\n",
            "COT_zeroshot_llm_1 241.19 22.97\n",
            "COT_llm_1 235.11 23.84\n",
            "\n",
            "nocall_2 77.0 11.79\n",
            "random_2 85.75 12.95\n",
            "base_2 101.78 20.09\n",
            "human_2 102.51 18.39\n",
            "llm_2 101.88 18.62\n",
            "zeroshot_llm_2 101.27 19.01\n",
            "COT_zeroshot_llm_2 95.97 16.04\n",
            "COT_llm_2 95.69 20.34\n",
            "\n",
            "nocall_3 331.27 3.58\n",
            "random_3 347.11 2.09\n",
            "base_3 373.45 18.41\n",
            "human_3 370.27 16.4\n",
            "llm_3 372.09 19.2\n",
            "zeroshot_llm_3 369.24 17.65\n",
            "COT_zeroshot_llm_3 373.45 21.9\n",
            "COT_llm_3 367.61 18.38\n",
            "\n",
            "nocall_4 157.35 16.18\n",
            "random_4 173.25 15.85\n",
            "base_4 196.64 18.0\n",
            "human_4 195.38 25.12\n",
            "llm_4 194.18 30.42\n",
            "zeroshot_llm_4 187.97 31.17\n",
            "COT_zeroshot_llm_4 202.43 15.95\n",
            "COT_llm_4 188.55 21.31\n",
            "\n",
            "nocall_5 23.21 6.27\n",
            "random_5 25.67 6.47\n",
            "base_5 30.82 9.37\n",
            "human_5 30.38 8.01\n",
            "llm_5 27.2 8.27\n",
            "zeroshot_llm_5 27.45 6.58\n",
            "COT_zeroshot_llm_5 26.93 8.16\n",
            "COT_llm_5 26.48 7.64\n",
            "\n",
            "nocall_6 217.39 10.16\n",
            "random_6 233.21 10.74\n",
            "base_6 254.38 23.06\n",
            "human_6 261.92 20.25\n",
            "llm_6 259.47 22.84\n",
            "zeroshot_llm_6 265.01 20.95\n",
            "COT_zeroshot_llm_6 246.33 24.07\n",
            "COT_llm_6 262.16 24.08\n",
            "\n",
            "nocall_7 165.14 11.02\n",
            "random_7 181.01 11.15\n",
            "base_7 204.81 17.94\n",
            "human_7 205.7 19.15\n",
            "llm_7 212.8 14.62\n",
            "zeroshot_llm_7 210.5 23.43\n",
            "COT_zeroshot_llm_7 202.37 23.27\n",
            "COT_llm_7 198.98 20.36\n",
            "\n",
            "nocall_8 138.5 3.27\n",
            "random_8 154.39 2.34\n",
            "base_8 176.65 17.25\n",
            "human_8 178.83 18.98\n",
            "llm_8 168.69 21.09\n",
            "zeroshot_llm_8 168.15 19.86\n",
            "COT_zeroshot_llm_8 173.52 17.49\n",
            "COT_llm_8 166.3 22.39\n",
            "\n",
            "nocall_9 140.62 5.63\n",
            "random_9 156.39 4.16\n",
            "base_9 181.19 21.16\n",
            "human_9 183.53 22.83\n",
            "llm_9 180.16 16.3\n",
            "zeroshot_llm_9 175.01 24.16\n",
            "COT_zeroshot_llm_9 179.72 22.87\n",
            "COT_llm_9 169.49 21.45\n",
            "\n",
            "nocall_10 164.0 7.98\n",
            "random_10 179.76 7.32\n",
            "base_10 200.48 23.62\n",
            "human_10 205.47 23.91\n",
            "llm_10 204.05 15.71\n",
            "zeroshot_llm_10 206.31 22.7\n",
            "COT_zeroshot_llm_10 208.05 16.87\n",
            "COT_llm_10 189.6 17.57\n",
            "\n",
            "nocall_11 152.58 11.47\n",
            "random_11 168.53 10.76\n",
            "base_11 192.54 21.12\n",
            "human_11 195.46 24.07\n",
            "llm_11 188.28 33.49\n",
            "zeroshot_llm_11 193.43 14.8\n",
            "COT_zeroshot_llm_11 173.31 25.96\n",
            "COT_llm_11 191.84 24.31\n",
            "\n",
            "nocall_12 163.21 8.66\n",
            "random_12 179.01 8.58\n",
            "base_12 201.62 14.6\n",
            "human_12 201.93 14.87\n",
            "llm_12 187.54 21.97\n",
            "zeroshot_llm_12 199.13 21.03\n",
            "COT_zeroshot_llm_12 190.3 18.2\n",
            "COT_llm_12 203.73 17.62\n",
            "\n",
            "nocall_13 237.51 13.6\n",
            "random_13 253.28 12.92\n",
            "base_13 282.75 20.71\n",
            "human_13 281.34 17.44\n",
            "llm_13 273.95 20.97\n",
            "zeroshot_llm_13 276.21 31.44\n",
            "COT_zeroshot_llm_13 276.42 19.55\n",
            "COT_llm_13 271.51 26.61\n",
            "\n",
            "nocall_14 152.83 11.3\n",
            "random_14 168.64 9.61\n",
            "base_14 194.0 22.8\n",
            "human_14 196.78 20.0\n",
            "llm_14 182.29 14.43\n",
            "zeroshot_llm_14 191.48 17.39\n",
            "COT_zeroshot_llm_14 183.74 21.04\n",
            "COT_llm_14 190.62 20.2\n",
            "\n",
            "nocall_15 118.87 18.41\n",
            "random_15 126.32 19.4\n",
            "base_15 139.24 19.9\n",
            "human_15 135.03 20.7\n",
            "llm_15 138.63 24.48\n",
            "zeroshot_llm_15 130.62 19.47\n",
            "COT_zeroshot_llm_15 138.13 22.19\n",
            "COT_llm_15 142.95 23.26\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "results_matrix = [[] for i in range(16)]\n",
        "std_matrix = [[] for i in range(16)]\n",
        "for i in range(16):\n",
        "    for rew in ['nocall', 'random', 'base', 'human', 'llm', 'zeroshot_llm', 'COT_zeroshot_llm', 'COT_llm']:\n",
        "        k = f\"{rew}_{i}\"\n",
        "        print(k, round(np.mean(res[k]), 2), round(np.std(res[k]), 2))\n",
        "        results_matrix[i].append(np.mean(res[k]))\n",
        "        std_matrix[i].append(np.std(res[k]))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[161.2 175.2 197.2 198.9 193.1 194.  192.5 192.3]\n",
            " [ 10.    9.6  18.7  18.8  21.1  20.9  20.   20.7]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(precision=1)\n",
        "mu, std = np.array(results_matrix).mean(axis=0), np.array(std_matrix).mean(axis=0)\n",
        "print(np.vstack((mu, std)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
