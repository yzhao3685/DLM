{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Getting page 2\n",
            "Getting page 3\n",
            "Getting page 4\n",
            "Getting page 5\n",
            "Getting page 6\n",
            "Getting page 7\n",
            "5759\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import datetime\n",
        "import pytz\n",
        "\n",
        "\n",
        "url = \"https://logs.betterstack.com/api/v1/query\"\n",
        "headers = {\n",
        "    \"Authorization\": \"Bearer 2oqgnLmr2d6QaNyEzS4FCv96\",\n",
        "}\n",
        "\n",
        "def get_data(params):\n",
        "    i = 2\n",
        "    params = {**params, \"batch\": 1000}\n",
        "    response = requests.get(url, headers=headers, params=params).json()\n",
        "    # add pagination\n",
        "    ret = response['data']\n",
        "    while response['pagination']['next'] and response['data']:\n",
        "        next_url = response['pagination']['next']\n",
        "        print('Getting page', i)\n",
        "        response = requests.get(next_url, headers=headers).json()\n",
        "        ret.extend(response['data'])\n",
        "        i += 1\n",
        "    return ret\n",
        "\n",
        "# 2024-02-14T11:49:58.747138+00:00\n",
        "# data = get_data({\"from\": \"2022-07-19T13:32:56+00:00\", \"to\": \"2025-07-19T13:32:56+00:00\"})\n",
        "\n",
        "\n",
        "data = get_data({\"from\": datetime.datetime(2024, 2, 15, 12, 00, 0, tzinfo=pytz.timezone('EST')).isoformat(), \n",
        "                 \"to\": datetime.datetime(2025, 2, 14, 3, 14, 0, tzinfo=pytz.timezone('EST')).isoformat()})\n",
        "\n",
        "print(len(data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "finished = []\n",
        "for d in data:\n",
        "    if 'Finished' in d['message'] and 'job!' in d['message']:\n",
        "        finished.append(int(d['message'].split(' ')[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1275"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(finished)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'dt': '2024-02-15 17:14:53.499400',\n",
              " '_dt': '1708017293499400',\n",
              " '_insert_index': 134000001,\n",
              " 'json': '{\"context\":{\"runtime\":{\"file\":\"gemini.py\",\"function\":\"main\",\"line\":324,\"logger_name\":\"__main__\",\"thread_id\":140392704377216,\"thread_name\":\"MainThread\"},\"system\":{\"pid\":83,\"process_name\":\"MainProcess\"}},\"dt\":\"2024-02-15T17:14:53.499400+00:00\",\"extra\":{},\"filename\":\"gemini.py\",\"level\":\"info\",\"message\":\"START:800, END:880\",\"severity\":2}',\n",
              " '_app': 'reward_learning',\n",
              " '_source_id': '682629',\n",
              " 'level': 'info',\n",
              " 'message': 'START:800, END:880'}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5759"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Failed:  [118, 728, 160, 0, 240]\n",
            "Number Results:  3811\n",
            "Finished: 1275\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "fin = []\n",
        "failed = []\n",
        "results = {}\n",
        "for i in data:\n",
        "    if 'Finished' in i['message']:\n",
        "        try:\n",
        "            fin.append(int(i['message'].split(' ')[1]))\n",
        "        except ValueError:\n",
        "            # print(i['message'])\n",
        "            continue\n",
        "    elif 'Failed' in i['message']:\n",
        "        try:\n",
        "            failed.append(int(i[\"message\"].split(\" \")[1]))\n",
        "        except ValueError:\n",
        "            print(i[\"message\"])\n",
        "    elif len([rm for rm in ['START', 'Config', 'Upload folder did not work'] if rm in i['message']]):\n",
        "        continue\n",
        "    else:\n",
        "        try:\n",
        "            results[i['message']] = json.loads(i['json'])['message_json']\n",
        "        except KeyError:\n",
        "            continue\n",
        "            # print(i['message'])\n",
        "print('Failed: ', failed)\n",
        "print('Number Results: ', len(results))\n",
        "print('Finished:', len(fin))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['reward',\n",
              " '1708017293.7281098',\n",
              " 'rfbase',\n",
              " 'cotTrue',\n",
              " 'seed4',\n",
              " 'nepochs1',\n",
              " 'task',\n",
              " 'index=15',\n",
              " 'stage=0',\n",
              " 'iteration=0//logs/results/REWARDS',\n",
              " 'TASK15',\n",
              " 'REWbase',\n",
              " 'N48',\n",
              " 'B16',\n",
              " 'OPT0.9::']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keys = list(results.keys())\n",
        "\n",
        "keys[0].split('_')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from typing import Callable, NewType\n",
        "import numpy.typing as npt\n",
        "import numpy as np\n",
        "\n",
        "RewardFun = Callable[[npt.NDArray, int], float]  # RewardFun(feature, state) -> r\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Task:\n",
        "    command: str\n",
        "    base: RewardFun\n",
        "    human: RewardFun\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "types of tasks:\n",
        "1) take tail of one feature distribution\n",
        "2) take lower and upper bound of one feature distribution\n",
        "3) combine two feature distributions\n",
        "4) use latent label that requires inference (previously impoverished, now impoverished, most at risk (mothers previously suffering from miscarriage or complications))\n",
        " \n",
        "These categories can then vary  by weight: focus slightly more, focus heavily, focus solely on\n",
        " \n",
        "And do this for every feature. \n",
        " \n",
        "This is already 4 x 3 = 240 tasks.\n",
        " \n",
        " We can also add negatives (slightly defocus/disadvantage/deprioritize) to get 240 * 2 = 480 tasks.\n",
        " \n",
        "4) take tail of one feature distribution and combine with another feature distribution\n",
        "5) take lower and upper bound of one feature distribution and combine with another feature distribution,\n",
        "6) combine two feature distributions and combine with another feature distribution\n",
        "7) take tail of one feature distribution and combine with another feature distribution and combine with another feature distribution\n",
        "8) take lower and upper bound of one feature distribution and combine with another feature distribution and combine with another feature distribution\n",
        " \n",
        "\"\"\"\n",
        "# task_commands = [\n",
        "#     # 1) Take tail of one feature distribution\n",
        "#     \"Identify the upper 10% of beneficiaries by age distribution.\",\n",
        "#     \"Extract the highest income_bracket distribution tail, focusing on the top 5%.\",\n",
        "#     \"Select the tail end of the 'duration' distribution to analyze the longest calls made to beneficiaries.\",\n",
        "#     \"Find the tail of the 'g' distribution representing the most pregnancies.\",\n",
        "#     \"Retrieve the tail distribution for 'attempt_no' to see the most frequent call attempt numbers.\",\n",
        "#     # \" 2) Take lower and upper bound of one feature distribution\",\n",
        "#     \"Determine the lower and upper quartile for the age feature.\",\n",
        "#     \"Calculate the income_bracket bounds for the middle 50% of the population.\",\n",
        "#     \"Find the boundaries of the 'duration' feature where 90% of the calls lie within.\",\n",
        "#     \"Establish the lower and upper bounds of 'enrollment_gestation_age' for the central 80% of the data.\",\n",
        "#     \"Set the thresholds for the 'l' feature to identify the common range of live births.\",\n",
        "#     # \" 3) Combine two feature distributions\",\n",
        "#     \"Combine the distributions of 'age' and 'education' to identify the correlation between the beneficiary's age and their educational attainment.\",\n",
        "#     \"Create a joint distribution of 'income_bracket' and 'phone_owner' to explore the financial status against phone ownership.\",\n",
        "#     \"Merge the 'slot' and 'duration' distributions to see if certain call times correlate with longer message listening durations.\",\n",
        "#     \"Integrate the distributions of 'g' (gravidity) and 'p' (parity) to analyze pregnancy and viable gestational ages together.\",\n",
        "#     \"Combine 'language_name' with 'Technical_success' to assess if the success of calls varies with language preferences.\",\n",
        "#     # \" 4) Use latent label that requires inference (previously impoverished, now impoverished, most at risk)\",\n",
        "#     \"Infer financial improvement by comparing past and present 'income_bracket' to label beneficiaries as 'previously impoverished' or 'now impoverished'.\",\n",
        "#     \"Identify 'most at risk' mothers by selecting those with a history of 's' (stillbirths) or who had complications mentioned in 'education' notes.\",\n",
        "#     \"Filter for beneficiaries who moved from the lowest 'income_bracket' and are not in the lowest anymore to infer economic improvement.\",\n",
        "#     \"Apply inference rules to 'age' and 'p' to identify mothers at high risk due to age and number of past pregnancies.\",\n",
        "#     \"Cross-reference 'Technical_success' with repeat 'attempt_no' to infer technical challenges that could indicate 'at-risk' beneficiaries due to poor connectivity or other issues.\",\n",
        "# ]\n",
        "\n",
        "\n",
        "SLIGHTLY_MODIFIER = 0.5\n",
        "HEAVILY_MODIFIER = 1\n",
        "\n",
        "\n",
        "def if_(x: bool):\n",
        "    return 1.0 if x else 0.0\n",
        "\n",
        "\n",
        "# TODO: compare this with the diversity of the actual dataset. for each task, how many people in the dataset does this actually apply to?\n",
        "# 01/24/24 removed abortion, subtract by one most indices\n",
        "# 02/12/24 remove stillbirth and infer. stillbirth gets 0 reward, and infer is too hard\n",
        "task_commands = [\n",
        "    # 1) Take tail of one feature distribution\n",
        "    Task(\n",
        "        \"Focus slightly on the most elderly by age distribution.\",\n",
        "        lambda feature, state: state + SLIGHTLY_MODIFIER * feature[12 - 1],\n",
        "        lambda feature, state: state**2 + SLIGHTLY_MODIFIER * feature[12 - 1],\n",
        "    ),\n",
        "    Task(\n",
        "        \"The lowest income_bracket distribution tail is very important, focus heavily on the top 12.5%.\",\n",
        "        lambda feature, state: state + HEAVILY_MODIFIER * feature[37 - 1],\n",
        "        lambda feature, state: state**2 + HEAVILY_MODIFIER * feature[37 - 1],\n",
        "    ),\n",
        "    Task(\n",
        "        \"Select solely those who speak Hindi to analyze how this would affect the calls made to our beneficiaries.\",\n",
        "        lambda feature, state: state * if_(feature[13 - 1]),\n",
        "        lambda feature, state: state**2 * if_(feature[13 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Priortize slightly those who have had prior pregnancies.\",  # g feature\n",
        "        lambda feature, state: state + SLIGHTLY_MODIFIER * if_(feature[2]),\n",
        "        lambda feature, state: state**2 + SLIGHTLY_MODIFIER * if_(feature[2]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Heavily weight those who have had low education.\",  # education_1\n",
        "        lambda feature, state: state + HEAVILY_MODIFIER * if_(feature[17 - 1]),\n",
        "        lambda feature, state: state**2 + HEAVILY_MODIFIER * if_(feature[17 - 1]),\n",
        "    ),\n",
        "    # \" 2) Take lower and upper bound of one feature distribution\",\n",
        "    Task(\n",
        "        \"Focus only on both the young and elderly.\",  # education_1\n",
        "        lambda feature, state: state * if_(feature[12 - 1] or feature[8 - 1]),\n",
        "        lambda feature, state: state**2 * if_(feature[12 - 1] or feature[8 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Prefer slightly on the income_bracket bounds for the middle 40% of the population.\",  # income_bracker 3, 4, 5\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(feature[39 - 1] or feature[40 - 1] or feature[41 - 1]),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(feature[39 - 1] or feature[40 - 1] or feature[41 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Slightly favor those women who do not own their own phone\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[25 - 1] or feature[26 - 1]),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[25 - 1] or feature[26 - 1]),\n",
        "    ),\n",
        "    # \"Establish the lower and upper bounds of 'enrollment_gestation_age' for the central 80% of the data.\",\n",
        "    # \"Set the thresholds for the 'l' feature to identify the common range of live births.\",\n",
        "    # \" 3) Combine two feature distributions\",\n",
        "    Task(\n",
        "        \"Combine the distributions of 'age' and 'education' to heavily give precedence to low income impoverished youth.\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[8 - 1] and feature[17 - 1]),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[8 - 1] and feature[17 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Focus slightly on the joint distribution of 'income_bracket' and 'phone_owner' for those with high financial status but with no phone ownership.\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(\n",
        "            (feature[40 - 1] or feature[41 - 1])\n",
        "            and (feature[25 - 1] or feature[26 - 1])\n",
        "        ),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(\n",
        "            (feature[40 - 1] or feature[41 - 1])\n",
        "            and (feature[25 - 1] or feature[26 - 1])\n",
        "        ),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Advantage slightly those who prefer being called after 7PM 'slot' registered at an NGO.\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[32 - 1] and feature[33 - 1]),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[32 - 1] and feature[33 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Integrate the distributions of 'g' (gravidity) and 'l' (live) to concentrate heavily on mothers who have several pregnancies but not much success with birth\",\n",
        "        lambda feature, state: state\n",
        "        + HEAVILY_MODIFIER * if_(feature[2] > 1 and feature[5] == 0),\n",
        "        lambda feature, state: state**2\n",
        "        + HEAVILY_MODIFIER * if_(feature[2] > 1 and feature[5] == 0),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Slightly fixate on those Marathi-speakers with middle-aged folks.\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(feature[14 - 1] and (feature[10 - 1] or feature[11 - 1])),\n",
        "        lambda feature, state: state**2\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * if_(feature[14 - 1] and (feature[10 - 1] or feature[11 - 1])),\n",
        "    ),\n",
        "    # \" 4) Use latent label that requires inference (previously impoverished, now impoverished, most at risk)\",\n",
        "    # Task(\n",
        "    #     \"Infer disempowered mothers with little opportunity and focus heavily on them.\",  # mothers with low education, low income, and no phone ownership\n",
        "    #     lambda feature, state: state\n",
        "    #     + HEAVILY_MODIFIER\n",
        "    #     * if_(\n",
        "    #         feature[14-1]\n",
        "    #         and (feature[25-1] or feature[26-1])\n",
        "    #         and (feature[37-1] or feature[38-1]),\n",
        "    #         lambda feature, state: state**2\n",
        "    #         + SLIGHTLY_MODIFIER * if_(feature[14-1] and (feature[25-1] or feature[26-1])),\n",
        "    #     ),\n",
        "    #     lambda feature, state: state**2\n",
        "    #     + HEAVILY_MODIFIER\n",
        "    #     * if_(\n",
        "    #         feature[14-1]\n",
        "    #         and (feature[25-1] or feature[26-1])\n",
        "    #         and (feature[37-1] or feature[38-1]),\n",
        "    #         lambda feature, state: state**2\n",
        "    #         + SLIGHTLY_MODIFIER * if_(feature[14-1] and (feature[25-1] or feature[26-1])),\n",
        "    #     ),\n",
        "    # ),\n",
        "    # Task(\n",
        "    #     \"Identify 'most at risk' mothers by selecting those with a history of 's' (stillbirths) and have had little education and prefer them solely.\",\n",
        "    #     lambda feature, state: state * if_(feature[4] and (feature[17-1] or feature[18-1])),\n",
        "    #     lambda feature, state: (state**2)\n",
        "    #     * if_(feature[4] and (feature[17-1] or feature[18-1])),\n",
        "    # ),\n",
        "    Task(\n",
        "        \"Give slightly more attention for beneficiaries who likely work early in the morning and late at night.\",\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[27 - 1] or feature[29 - 1]),\n",
        "        lambda feature, state: (state**2)\n",
        "        + SLIGHTLY_MODIFIER * if_(feature[27 - 1] or feature[29 - 1]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Apply inference rules to 'age' and 'p' to identify mothers at high risk due to age and number of past pregnancies and focus heavily on them.\",\n",
        "        lambda feature, state: state\n",
        "        + HEAVILY_MODIFIER * if_((feature[11 - 1] or feature[12 - 1]) and feature[3]),\n",
        "        lambda feature, state: (state**2)\n",
        "        + HEAVILY_MODIFIER * if_((feature[11 - 1] or feature[12 - 1]) and feature[3]),\n",
        "    ),\n",
        "    Task(\n",
        "        \"Infer technical challenges in reaching the phone that could indicate 'at-risk' beneficiaries and give preference slightly.\",  # this just means phone ownership or potentially low income, but requires inference.\n",
        "        lambda feature, state: state\n",
        "        + SLIGHTLY_MODIFIER * if_((feature[25 - 1] or feature[26 - 1]))\n",
        "        and feature[3],\n",
        "        lambda feature, state: (state**2)\n",
        "        + SLIGHTLY_MODIFIER * if_((feature[25 - 1] or feature[26 - 1]))\n",
        "        + SLIGHTLY_MODIFIER\n",
        "        * 0.2\n",
        "        * if_((feature[37 - 1] or feature[38 - 1])),  # slight weighting for low income\n",
        "    ),\n",
        "]\n",
        "\n",
        "\n",
        "# TODO: state**2 == state since state \\in {0, 1}? potential answer: squaring the full output of the reward for shaped reward\n",
        "# now we wrap the shap\n",
        "def shaped_wrapper(reward_fun: RewardFun) -> RewardFun:\n",
        "    def shaped_reward(feature: npt.NDArray, state: int) -> float:\n",
        "        return reward_fun(feature, state) ** 2\n",
        "\n",
        "    return shaped_reward\n",
        "\n",
        "\n",
        "TASKS = []\n",
        "for command in task_commands:\n",
        "    command.human = shaped_wrapper(command.human)\n",
        "    TASKS.append(command)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from itertools import product\n",
        "\n",
        "def get_user_defined_attrs(cls) -> list:\n",
        "    return [\n",
        "        attr\n",
        "        for attr in dir(cls)\n",
        "        if not callable(getattr(cls, attr)) and not attr.startswith(\"__\")\n",
        "    ]\n",
        "\n",
        "\n",
        "class BaseHyperParameters:\n",
        "    @classmethod\n",
        "    def get_product(cls):\n",
        "        return list(\n",
        "            product(*[getattr(cls, attr) for attr in get_user_defined_attrs(cls)])\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class HyperParameters(BaseHyperParameters):\n",
        "    # TODO figure out better way to sort attrs without having to add number in beginning, and tie this so there's never a bug with reading the variables below    \n",
        "    _1_arm_budget = [(48, 16), (21, 7)]\n",
        "    # _2_arm_budget = [(48, 16)]\n",
        "    _2_cot = [True, False]    \n",
        "    _3_seeds = list(range(17)) + [12, 13, 42]\n",
        "    _4_task_indices = range(len(TASKS))\n",
        "    _5_n_train_epochs = [1, 3, 5]\n",
        "    _6_llm_reward = [True, False]\n",
        "\n",
        "\n",
        "\n",
        "og_hparams = HyperParameters.get_product()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class HyperParameters:\n",
        "    # alphabetical\n",
        "    _1_llm_reward: str\n",
        "    _2_arm_budget: int\n",
        "    _3_cot: bool\n",
        "    _4_seeds: int\n",
        "    _5_task_indices: int\n",
        "    _6_n_epochs: int\n",
        "    _stage: int\n",
        "    _iteration: int\n",
        "    \n",
        "\n",
        "\n",
        "def get_vars(key):\n",
        "    try:\n",
        "        _, time, _, cot, seed, n_epochs, _, task, stage, iteration, _, reward_type, arms, budget, optin = key.split('_')\n",
        "    except ValueError as e:\n",
        "        print(key.split('_'))\n",
        "        raise e\n",
        "    cot = eval(cot[3:])\n",
        "    budget = int(budget[1:])\n",
        "    arms = int(arms[1:])\n",
        "    seed = int(seed[4:])\n",
        "    stage = int(stage.split('=')[1])\n",
        "    task = int(task.split('=')[1])\n",
        "    iteration = int(iteration.split('=')[1].split('//')[0])\n",
        "\n",
        "    return HyperParameters(reward_type, arms, cot, seed, task, n_epochs, stage, iteration)\n",
        "\n",
        "\n",
        "hparams = [get_vars(k) for k in keys]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1152\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "3811"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(192 * 4 + 192 + 192)\n",
        "len(hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">dict\n",
              "├── <span style=\"font-weight: bold\">No Calls</span>\n",
              "│   └── dict\n",
              "│       ├── <span style=\"font-weight: bold\">all</span>\n",
              "│       │   └── list[50]\n",
              "│       │       ├── float: <span style=\"color: #000080; text-decoration-color: #000080\">154.0</span>\n",
              "│       │       ├── float: <span style=\"color: #000080; text-decoration-color: #000080\">85.0</span>\n",
              "│       │       ├── float: <span style=\"color: #000080; text-decoration-color: #000080\">89.0</span>\n",
              "│       │       └── ...\n",
              "│       ├── <span style=\"font-weight: bold\">err</span>\n",
              "│       │   └── float: <span style=\"color: #000080; text-decoration-color: #000080\">10.659756094770648</span>\n",
              "│       └── <span style=\"font-weight: bold\">val</span>\n",
              "│           └── float: <span style=\"color: #000080; text-decoration-color: #000080\">89.64</span>\n",
              "├── <span style=\"font-weight: bold\">PreFeRMAB</span>\n",
              "│   └── dict\n",
              "│       ├── <span style=\"font-weight: bold\">all</span>\n",
              "│       │   └── list[50]\n",
              "│       │       ├── float: <span style=\"color: #000080; text-decoration-color: #000080\">120.0</span>\n",
              "│       │       ├── float: <span style=\"color: #000080; text-decoration-color: #000080\">104.0</span>\n",
              "│       │       ├── float: <span style=\"color: #000080; text-decoration-color: #000080\">118.0</span>\n",
              "│       │       └── ...\n",
              "│       ├── <span style=\"font-weight: bold\">err</span>\n",
              "│       │   └── float: <span style=\"color: #000080; text-decoration-color: #000080\">9.953270819183007</span>\n",
              "│       └── <span style=\"font-weight: bold\">val</span>\n",
              "│           └── float: <span style=\"color: #000080; text-decoration-color: #000080\">117.18</span>\n",
              "└── <span style=\"font-weight: bold\">RandomDS</span>\n",
              "    └── dict\n",
              "        ├── <span style=\"font-weight: bold\">all</span>\n",
              "        │   └── list[50]\n",
              "        │       ├── float: <span style=\"color: #000080; text-decoration-color: #000080\">112.0</span>\n",
              "        │       ├── float: <span style=\"color: #000080; text-decoration-color: #000080\">93.0</span>\n",
              "        │       ├── float: <span style=\"color: #000080; text-decoration-color: #000080\">97.0</span>\n",
              "        │       └── ...\n",
              "        ├── <span style=\"font-weight: bold\">err</span>\n",
              "        │   └── float: <span style=\"color: #000080; text-decoration-color: #000080\">6.406122071893416</span>\n",
              "        └── <span style=\"font-weight: bold\">val</span>\n",
              "            └── float: <span style=\"color: #000080; text-decoration-color: #000080\">96.04</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "dict\n",
              "├── \u001b[1mNo Calls\u001b[0m\n",
              "│   └── dict\n",
              "│       ├── \u001b[1mall\u001b[0m\n",
              "│       │   └── list[50]\n",
              "│       │       ├── float: \u001b[34m154.0\u001b[0m\n",
              "│       │       ├── float: \u001b[34m85.0\u001b[0m\n",
              "│       │       ├── float: \u001b[34m89.0\u001b[0m\n",
              "│       │       └── ...\n",
              "│       ├── \u001b[1merr\u001b[0m\n",
              "│       │   └── float: \u001b[34m10.659756094770648\u001b[0m\n",
              "│       └── \u001b[1mval\u001b[0m\n",
              "│           └── float: \u001b[34m89.64\u001b[0m\n",
              "├── \u001b[1mPreFeRMAB\u001b[0m\n",
              "│   └── dict\n",
              "│       ├── \u001b[1mall\u001b[0m\n",
              "│       │   └── list[50]\n",
              "│       │       ├── float: \u001b[34m120.0\u001b[0m\n",
              "│       │       ├── float: \u001b[34m104.0\u001b[0m\n",
              "│       │       ├── float: \u001b[34m118.0\u001b[0m\n",
              "│       │       └── ...\n",
              "│       ├── \u001b[1merr\u001b[0m\n",
              "│       │   └── float: \u001b[34m9.953270819183007\u001b[0m\n",
              "│       └── \u001b[1mval\u001b[0m\n",
              "│           └── float: \u001b[34m117.18\u001b[0m\n",
              "└── \u001b[1mRandomDS\u001b[0m\n",
              "    └── dict\n",
              "        ├── \u001b[1mall\u001b[0m\n",
              "        │   └── list[50]\n",
              "        │       ├── float: \u001b[34m112.0\u001b[0m\n",
              "        │       ├── float: \u001b[34m93.0\u001b[0m\n",
              "        │       ├── float: \u001b[34m97.0\u001b[0m\n",
              "        │       └── ...\n",
              "        ├── \u001b[1merr\u001b[0m\n",
              "        │   └── float: \u001b[34m6.406122071893416\u001b[0m\n",
              "        └── \u001b[1mval\u001b[0m\n",
              "            └── float: \u001b[34m96.04\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from eztils.ezlogging import  inspect\n",
        "\n",
        "inspect(results[keys[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def print_results(num_arms):\n",
        "    # 48 budget results\n",
        "    np.set_printoptions(precision=1)\n",
        "    from collections import defaultdict\n",
        "    res = defaultdict(list)\n",
        "    for hparam, key in zip(hparams, keys):\n",
        "        if hparam._2_arm_budget == num_arms:\n",
        "            # print(key)\n",
        "            res[f\"nocall_{hparam._5_task_indices}\"].extend(\n",
        "                results[key][\"No Calls\"][\"all\"]\n",
        "            )\n",
        "            res[f\"random_{hparam._5_task_indices}\"].extend(results[key][\"RandomDS\"]['all'])\n",
        "            ret = results[key][\"PreFeRMAB\"]\n",
        "            k = f\"{hparam._1_llm_reward[3:]}_{hparam._5_task_indices}\"\n",
        "            # if k == 'REWbase_9':\n",
        "            # print(hparam)\n",
        "            if hparam._1_llm_reward != \"REWllm\" and hparam._3_cot:        \n",
        "                res[k].extend(ret['all'])\n",
        "                continue\n",
        "\n",
        "            # ignore zero shot for now\n",
        "            if hparam._stage == 0 and hparam._iteration == 0:\n",
        "                if hparam._3_cot:\n",
        "                    res['zeroshot_'+k].extend(ret['all'])\n",
        "                else:\n",
        "                    res['COT_zeroshot_'+k].extend(ret['all'])\n",
        "            if hparam._stage == 1 and hparam._iteration == 1:\n",
        "                if hparam._3_cot:\n",
        "                    res['COT_'+k].extend(ret['all'])\n",
        "                else:\n",
        "                    res[k].extend(ret['all'])\n",
        "\n",
        "    results_matrix = [[] for i in range(16)]\n",
        "    std_matrix = [[] for i in range(16)]\n",
        "    for i in range(16):\n",
        "        for rew in ['nocall', 'random', 'base', 'human', 'llm', 'zeroshot_llm', 'COT_zeroshot_llm', 'COT_llm']:\n",
        "            k = f\"{rew}_{i}\"\n",
        "            std_err = np.std(res[k]) / math.sqrt(10)\n",
        "            print(k, round(np.mean(res[k]), 2), round(std_err, 2))\n",
        "            results_matrix[i].append(np.mean(res[k]))\n",
        "            std_matrix[i].append(std_err)\n",
        "        print()           \n",
        "\n",
        "    mu, std = np.array(results_matrix).mean(axis=0), np.array(std_matrix).mean(axis=0)\n",
        "    print(np.vstack((mu, std)))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nocall_0 140.72 3.1\n",
            "random_0 156.46 2.81\n",
            "base_0 195.5 4.2\n",
            "human_0 195.32 4.28\n",
            "llm_0 169.86 7.4\n",
            "zeroshot_llm_0 170.21 7.17\n",
            "COT_zeroshot_llm_0 188.21 6.29\n",
            "COT_llm_0 177.51 7.81\n",
            "\n",
            "nocall_1 201.05 6.1\n",
            "random_1 216.75 5.83\n",
            "base_1 251.81 6.5\n",
            "human_1 255.93 7.35\n",
            "llm_1 239.72 8.41\n",
            "zeroshot_llm_1 238.84 9.08\n",
            "COT_zeroshot_llm_1 226.63 9.79\n",
            "COT_llm_1 239.86 10.15\n",
            "\n",
            "nocall_2 82.38 4.3\n",
            "random_2 91.82 4.66\n",
            "base_2 114.89 5.56\n",
            "human_2 115.95 5.91\n",
            "llm_2 103.56 6.89\n",
            "zeroshot_llm_2 110.69 6.9\n",
            "COT_zeroshot_llm_2 104.37 6.61\n",
            "COT_llm_2 106.26 7.9\n",
            "\n",
            "nocall_3 331.31 2.96\n",
            "random_3 347.03 2.59\n",
            "base_3 386.62 3.62\n",
            "human_3 384.84 3.6\n",
            "llm_3 385.82 3.62\n",
            "zeroshot_llm_3 380.96 6.24\n",
            "COT_zeroshot_llm_3 379.2 6.01\n",
            "COT_llm_3 384.96 3.2\n",
            "\n",
            "nocall_4 160.42 6.12\n",
            "random_4 176.07 6.04\n",
            "base_4 216.69 6.65\n",
            "human_4 215.1 7.04\n",
            "llm_4 215.83 6.61\n",
            "zeroshot_llm_4 204.41 8.68\n",
            "COT_zeroshot_llm_4 201.89 5.43\n",
            "COT_llm_4 211.81 6.13\n",
            "\n",
            "nocall_5 21.6 2.8\n",
            "random_5 23.96 3.0\n",
            "base_5 30.16 3.99\n",
            "human_5 31.17 4.05\n",
            "llm_5 25.1 3.4\n",
            "zeroshot_llm_5 27.28 3.27\n",
            "COT_zeroshot_llm_5 26.79 3.63\n",
            "COT_llm_5 26.98 3.47\n",
            "\n",
            "nocall_6 218.74 4.01\n",
            "random_6 234.42 4.04\n",
            "base_6 272.89 4.84\n",
            "human_6 272.21 4.8\n",
            "llm_6 263.77 6.49\n",
            "zeroshot_llm_6 254.85 8.0\n",
            "COT_zeroshot_llm_6 260.0 7.4\n",
            "COT_llm_6 264.44 5.9\n",
            "\n",
            "nocall_7 162.08 4.52\n",
            "random_7 177.8 4.37\n",
            "base_7 213.82 4.66\n",
            "human_7 216.27 4.54\n",
            "llm_7 208.76 5.45\n",
            "zeroshot_llm_7 201.99 7.65\n",
            "COT_zeroshot_llm_7 206.03 8.12\n",
            "COT_llm_7 204.38 7.39\n",
            "\n",
            "nocall_8 138.74 2.97\n",
            "random_8 154.34 2.65\n",
            "base_8 192.6 3.56\n",
            "human_8 192.72 4.05\n",
            "llm_8 170.99 6.85\n",
            "zeroshot_llm_8 166.93 5.92\n",
            "COT_zeroshot_llm_8 165.77 6.66\n",
            "COT_llm_8 173.83 7.56\n",
            "\n",
            "nocall_9 141.99 3.27\n",
            "random_9 157.69 2.92\n",
            "base_9 194.04 3.33\n",
            "human_9 194.74 3.59\n",
            "llm_9 174.39 7.99\n",
            "zeroshot_llm_9 170.05 8.13\n",
            "COT_zeroshot_llm_9 168.48 7.72\n",
            "COT_llm_9 177.32 8.14\n",
            "\n",
            "nocall_10 164.15 4.08\n",
            "random_10 179.82 3.78\n",
            "base_10 217.5 4.79\n",
            "human_10 219.16 4.85\n",
            "llm_10 219.09 4.71\n",
            "zeroshot_llm_10 202.0 6.62\n",
            "COT_zeroshot_llm_10 211.88 6.6\n",
            "COT_llm_10 199.01 6.46\n",
            "\n",
            "nocall_11 153.05 4.18\n",
            "random_11 168.79 3.9\n",
            "base_11 202.94 5.36\n",
            "human_11 205.65 5.98\n",
            "llm_11 201.18 7.4\n",
            "zeroshot_llm_11 207.83 5.91\n",
            "COT_zeroshot_llm_11 201.83 8.39\n",
            "COT_llm_11 207.22 5.63\n",
            "\n",
            "nocall_12 162.02 3.81\n",
            "random_12 177.65 3.45\n",
            "base_12 220.33 4.53\n",
            "human_12 216.26 3.76\n",
            "llm_12 194.9 8.1\n",
            "zeroshot_llm_12 190.35 8.11\n",
            "COT_zeroshot_llm_12 197.26 7.72\n",
            "COT_llm_12 196.97 5.24\n",
            "\n",
            "nocall_13 232.99 5.24\n",
            "random_13 248.74 4.85\n",
            "base_13 290.76 4.97\n",
            "human_13 283.57 5.88\n",
            "llm_13 273.95 8.89\n",
            "zeroshot_llm_13 271.75 9.54\n",
            "COT_zeroshot_llm_13 270.95 10.45\n",
            "COT_llm_13 272.97 9.02\n",
            "\n",
            "nocall_14 155.37 4.97\n",
            "random_14 171.03 4.46\n",
            "base_14 209.74 5.08\n",
            "human_14 208.14 4.39\n",
            "llm_14 181.69 7.12\n",
            "zeroshot_llm_14 191.45 8.65\n",
            "COT_zeroshot_llm_14 192.88 9.86\n",
            "COT_llm_14 187.97 7.58\n",
            "\n",
            "nocall_15 117.03 6.41\n",
            "random_15 125.26 6.89\n",
            "base_15 146.3 8.81\n",
            "human_15 151.71 8.78\n",
            "llm_15 146.16 9.31\n",
            "zeroshot_llm_15 141.42 7.88\n",
            "COT_zeroshot_llm_15 138.92 6.94\n",
            "COT_llm_15 147.63 10.53\n",
            "\n",
            "[[161.5 175.5 209.8 209.9 198.4 195.7 196.3 198.7]\n",
            " [  4.3   4.1   5.    5.2   6.8   7.4   7.4   7. ]]\n"
          ]
        }
      ],
      "source": [
        "print_results(48)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nocall_0 62.62 1.77\n",
            "random_0 69.15 1.81\n",
            "base_0 85.88 2.46\n",
            "human_0 84.65 2.71\n",
            "llm_0 77.05 3.19\n",
            "zeroshot_llm_0 75.09 3.17\n",
            "COT_zeroshot_llm_0 75.97 3.02\n",
            "COT_llm_0 77.97 3.39\n",
            "\n",
            "nocall_1 87.15 4.0\n",
            "random_1 93.71 4.04\n",
            "base_1 106.49 3.94\n",
            "human_1 109.91 3.81\n",
            "llm_1 100.36 5.29\n",
            "zeroshot_llm_1 103.47 4.44\n",
            "COT_zeroshot_llm_1 99.35 5.38\n",
            "COT_llm_1 101.54 3.75\n",
            "\n",
            "nocall_2 35.31 2.17\n",
            "random_2 39.34 2.53\n",
            "base_2 48.68 3.36\n",
            "human_2 49.09 3.13\n",
            "llm_2 44.96 4.0\n",
            "zeroshot_llm_2 44.81 3.82\n",
            "COT_zeroshot_llm_2 42.96 4.08\n",
            "COT_llm_2 43.82 4.26\n",
            "\n",
            "nocall_3 146.08 1.67\n",
            "random_3 152.66 1.71\n",
            "base_3 169.7 2.36\n",
            "human_3 169.07 2.53\n",
            "llm_3 169.08 2.24\n",
            "zeroshot_llm_3 170.08 2.26\n",
            "COT_zeroshot_llm_3 167.51 2.5\n",
            "COT_llm_3 169.18 2.27\n",
            "\n",
            "nocall_4 71.28 3.14\n",
            "random_4 77.81 3.28\n",
            "base_4 94.3 3.04\n",
            "human_4 95.3 3.15\n",
            "llm_4 88.0 5.47\n",
            "zeroshot_llm_4 88.62 3.48\n",
            "COT_zeroshot_llm_4 88.42 2.97\n",
            "COT_llm_4 91.41 2.96\n",
            "\n",
            "nocall_5 9.86 1.61\n",
            "random_5 10.97 1.8\n",
            "base_5 14.24 2.51\n",
            "human_5 13.63 2.35\n",
            "llm_5 11.8 1.88\n",
            "zeroshot_llm_5 12.01 1.95\n",
            "COT_zeroshot_llm_5 11.86 1.91\n",
            "COT_llm_5 11.84 2.11\n",
            "\n",
            "nocall_6 99.73 2.91\n",
            "random_6 106.29 2.89\n",
            "base_6 121.42 3.83\n",
            "human_6 121.58 3.91\n",
            "llm_6 119.78 4.3\n",
            "zeroshot_llm_6 121.24 3.6\n",
            "COT_zeroshot_llm_6 117.72 3.14\n",
            "COT_llm_6 118.05 4.02\n",
            "\n",
            "nocall_7 70.11 2.01\n",
            "random_7 76.7 2.13\n",
            "base_7 92.78 2.07\n",
            "human_7 93.59 2.32\n",
            "llm_7 85.43 3.79\n",
            "zeroshot_llm_7 89.96 2.8\n",
            "COT_zeroshot_llm_7 82.37 4.4\n",
            "COT_llm_7 91.15 3.03\n",
            "\n",
            "nocall_8 61.38 1.67\n",
            "random_8 67.95 1.75\n",
            "base_8 83.59 2.39\n",
            "human_8 82.38 2.1\n",
            "llm_8 73.97 3.02\n",
            "zeroshot_llm_8 74.17 3.23\n",
            "COT_zeroshot_llm_8 76.05 3.51\n",
            "COT_llm_8 74.75 3.15\n",
            "\n",
            "nocall_9 63.12 1.97\n",
            "random_9 69.65 2.07\n",
            "base_9 86.41 2.29\n",
            "human_9 85.64 2.38\n",
            "llm_9 76.55 3.35\n",
            "zeroshot_llm_9 79.71 3.55\n",
            "COT_zeroshot_llm_9 75.86 3.67\n",
            "COT_llm_9 77.73 3.39\n",
            "\n",
            "nocall_10 70.74 2.07\n",
            "random_10 77.27 2.13\n",
            "base_10 94.4 1.98\n",
            "human_10 92.63 2.1\n",
            "llm_10 88.85 3.92\n",
            "zeroshot_llm_10 87.86 3.67\n",
            "COT_zeroshot_llm_10 91.86 2.45\n",
            "COT_llm_10 84.9 3.27\n",
            "\n",
            "nocall_11 73.34 3.47\n",
            "random_11 79.86 3.45\n",
            "base_11 93.67 3.88\n",
            "human_11 96.01 4.63\n",
            "llm_11 94.39 4.53\n",
            "zeroshot_llm_11 93.13 4.45\n",
            "COT_zeroshot_llm_11 93.43 5.13\n",
            "COT_llm_11 94.44 3.24\n",
            "\n",
            "nocall_12 70.12 2.72\n",
            "random_12 76.68 2.7\n",
            "base_12 92.71 2.75\n",
            "human_12 93.11 3.45\n",
            "llm_12 82.47 3.18\n",
            "zeroshot_llm_12 86.07 3.67\n",
            "COT_zeroshot_llm_12 83.99 3.13\n",
            "COT_llm_12 88.33 2.2\n",
            "\n",
            "nocall_13 104.61 3.58\n",
            "random_13 111.19 3.59\n",
            "base_13 127.16 4.08\n",
            "human_13 125.46 4.62\n",
            "llm_13 122.65 4.39\n",
            "zeroshot_llm_13 119.84 5.37\n",
            "COT_zeroshot_llm_13 122.25 4.71\n",
            "COT_llm_13 119.74 5.32\n",
            "\n",
            "nocall_14 67.95 2.43\n",
            "random_14 74.48 2.42\n",
            "base_14 91.84 3.19\n",
            "human_14 90.72 3.2\n",
            "llm_14 84.94 3.86\n",
            "zeroshot_llm_14 82.89 2.79\n",
            "COT_zeroshot_llm_14 79.75 3.42\n",
            "COT_llm_14 81.24 3.03\n",
            "\n",
            "nocall_15 43.36 4.69\n",
            "random_15 46.74 4.96\n",
            "base_15 56.95 5.56\n",
            "human_15 56.23 5.5\n",
            "llm_15 50.27 5.55\n",
            "zeroshot_llm_15 49.58 4.6\n",
            "COT_zeroshot_llm_15 50.94 5.93\n",
            "COT_llm_15 49.66 4.77\n",
            "\n",
            "[[71.  76.9 91.3 91.2 85.7 86.2 85.  86. ]\n",
            " [ 2.6  2.7  3.1  3.2  3.9  3.6  3.7  3.4]]\n"
          ]
        }
      ],
      "source": [
        "print_results(21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py311-torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
