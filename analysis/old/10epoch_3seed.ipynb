{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page 2\n",
      "Getting page 3\n",
      "1759\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "url = \"https://logs.betterstack.com/api/v1/query\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer 2oqgnLmr2d6QaNyEzS4FCv96\",\n",
    "}\n",
    "\n",
    "def get_data(params):\n",
    "    i = 2\n",
    "    params = {**params, \"batch\": 1000}\n",
    "    response = requests.get(url, headers=headers, params=params).json()\n",
    "    # add pagination\n",
    "    ret = response['data']\n",
    "    while response['pagination']['next'] and response['data']:\n",
    "        next_url = response['pagination']['next']\n",
    "        print('Getting page', i)\n",
    "        response = requests.get(next_url, headers=headers).json()\n",
    "        ret.extend(response['data'])\n",
    "        i += 1\n",
    "    return ret\n",
    "\n",
    "# 2024-02-14T11:49:58.747138+00:00\n",
    "# data = get_data({\"from\": \"2022-07-19T13:32:56+00:00\", \"to\": \"2025-07-19T13:32:56+00:00\"})\n",
    "\n",
    "data = get_data({\"from\": datetime.datetime(2024, 2, 14, 6, 49, 0, tzinfo=pytz.timezone('EST')).isoformat(), \n",
    "                 \"to\": datetime.datetime(2024, 2, 14, 8, 10, 0, tzinfo=pytz.timezone('EST')).isoformat()})\n",
    "\n",
    "print(len(data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "finished = []\n",
    "for d in data:\n",
    "    if 'Finished' in d['message'] and 'job!' in d['message']:\n",
    "        finished.append(int(d['message'].split(' ')[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finished)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt': '2024-02-14 11:49:58.747138',\n",
       " '_dt': '1707911398747138',\n",
       " '_insert_index': 134000010,\n",
       " 'json': '{\"context\":{\"runtime\":{\"file\":\"gemini.py\",\"function\":\"main\",\"line\":324,\"logger_name\":\"__main__\",\"thread_id\":140404180763008,\"thread_name\":\"MainThread\"},\"system\":{\"pid\":83,\"process_name\":\"MainProcess\"}},\"dt\":\"2024-02-14T11:49:58.747138+00:00\",\"extra\":{},\"filename\":\"gemini.py\",\"level\":\"info\",\"message\":\"START:24, END:48\",\"severity\":2}',\n",
       " '_app': 'reward_learning',\n",
       " '_source_id': '682629',\n",
       " 'level': 'info',\n",
       " 'message': 'START:24, END:48'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed:  []\n",
      "Number Results:  1149\n",
      "Finished: 384\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "fin = []\n",
    "failed = []\n",
    "results = {}\n",
    "for i in data:\n",
    "    if 'Finished' in i['message']:\n",
    "        try:\n",
    "            fin.append(int(i['message'].split(' ')[1]))\n",
    "        except ValueError:\n",
    "            # print(i['message'])\n",
    "            continue\n",
    "    elif 'Failed' in i['message']:\n",
    "        try:\n",
    "            failed.append(int(i[\"message\"].split(\" \")[1]))\n",
    "        except ValueError:\n",
    "            print(i[\"message\"])\n",
    "    elif len([rm for rm in ['START', 'Config', 'Upload folder did not work'] if rm in i['message']]):\n",
    "        continue\n",
    "    else:\n",
    "        try:\n",
    "            results[i['message']] = json.loads(i['json'])['message_json']\n",
    "        except KeyError:\n",
    "            continue\n",
    "            # print(i['message'])\n",
    "print('Failed: ', failed)\n",
    "print('Number Results: ', len(results))\n",
    "print('Finished:', len(fin))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reward',\n",
       " '1707911400.3069606',\n",
       " 'rfbase',\n",
       " 'cotTrue',\n",
       " 'seed42',\n",
       " 'task',\n",
       " 'index=3',\n",
       " 'stage=0',\n",
       " 'iteration=0//logs/results/REWARDS',\n",
       " 'TASK3',\n",
       " 'REWbase',\n",
       " 'N48',\n",
       " 'B16',\n",
       " 'OPT0.9::']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(results.keys())\n",
    "\n",
    "keys[0].split('_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable, NewType\n",
    "import numpy.typing as npt\n",
    "import numpy as np\n",
    "\n",
    "RewardFun = Callable[[npt.NDArray, int], float]  # RewardFun(feature, state) -> r\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Task:\n",
    "    command: str\n",
    "    base: RewardFun\n",
    "    human: RewardFun\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "types of tasks:\n",
    "1) take tail of one feature distribution\n",
    "2) take lower and upper bound of one feature distribution\n",
    "3) combine two feature distributions\n",
    "4) use latent label that requires inference (previously impoverished, now impoverished, most at risk (mothers previously suffering from miscarriage or complications))\n",
    " \n",
    "These categories can then vary  by weight: focus slightly more, focus heavily, focus solely on\n",
    " \n",
    "And do this for every feature. \n",
    " \n",
    "This is already 4 x 3 = 240 tasks.\n",
    " \n",
    " We can also add negatives (slightly defocus/disadvantage/deprioritize) to get 240 * 2 = 480 tasks.\n",
    " \n",
    "4) take tail of one feature distribution and combine with another feature distribution\n",
    "5) take lower and upper bound of one feature distribution and combine with another feature distribution,\n",
    "6) combine two feature distributions and combine with another feature distribution\n",
    "7) take tail of one feature distribution and combine with another feature distribution and combine with another feature distribution\n",
    "8) take lower and upper bound of one feature distribution and combine with another feature distribution and combine with another feature distribution\n",
    " \n",
    "\"\"\"\n",
    "# task_commands = [\n",
    "#     # 1) Take tail of one feature distribution\n",
    "#     \"Identify the upper 10% of beneficiaries by age distribution.\",\n",
    "#     \"Extract the highest income_bracket distribution tail, focusing on the top 5%.\",\n",
    "#     \"Select the tail end of the 'duration' distribution to analyze the longest calls made to beneficiaries.\",\n",
    "#     \"Find the tail of the 'g' distribution representing the most pregnancies.\",\n",
    "#     \"Retrieve the tail distribution for 'attempt_no' to see the most frequent call attempt numbers.\",\n",
    "#     # \" 2) Take lower and upper bound of one feature distribution\",\n",
    "#     \"Determine the lower and upper quartile for the age feature.\",\n",
    "#     \"Calculate the income_bracket bounds for the middle 50% of the population.\",\n",
    "#     \"Find the boundaries of the 'duration' feature where 90% of the calls lie within.\",\n",
    "#     \"Establish the lower and upper bounds of 'enrollment_gestation_age' for the central 80% of the data.\",\n",
    "#     \"Set the thresholds for the 'l' feature to identify the common range of live births.\",\n",
    "#     # \" 3) Combine two feature distributions\",\n",
    "#     \"Combine the distributions of 'age' and 'education' to identify the correlation between the beneficiary's age and their educational attainment.\",\n",
    "#     \"Create a joint distribution of 'income_bracket' and 'phone_owner' to explore the financial status against phone ownership.\",\n",
    "#     \"Merge the 'slot' and 'duration' distributions to see if certain call times correlate with longer message listening durations.\",\n",
    "#     \"Integrate the distributions of 'g' (gravidity) and 'p' (parity) to analyze pregnancy and viable gestational ages together.\",\n",
    "#     \"Combine 'language_name' with 'Technical_success' to assess if the success of calls varies with language preferences.\",\n",
    "#     # \" 4) Use latent label that requires inference (previously impoverished, now impoverished, most at risk)\",\n",
    "#     \"Infer financial improvement by comparing past and present 'income_bracket' to label beneficiaries as 'previously impoverished' or 'now impoverished'.\",\n",
    "#     \"Identify 'most at risk' mothers by selecting those with a history of 's' (stillbirths) or who had complications mentioned in 'education' notes.\",\n",
    "#     \"Filter for beneficiaries who moved from the lowest 'income_bracket' and are not in the lowest anymore to infer economic improvement.\",\n",
    "#     \"Apply inference rules to 'age' and 'p' to identify mothers at high risk due to age and number of past pregnancies.\",\n",
    "#     \"Cross-reference 'Technical_success' with repeat 'attempt_no' to infer technical challenges that could indicate 'at-risk' beneficiaries due to poor connectivity or other issues.\",\n",
    "# ]\n",
    "\n",
    "\n",
    "SLIGHTLY_MODIFIER = 0.5\n",
    "HEAVILY_MODIFIER = 1\n",
    "\n",
    "\n",
    "def if_(x: bool):\n",
    "    return 1.0 if x else 0.0\n",
    "\n",
    "\n",
    "# TODO: compare this with the diversity of the actual dataset. for each task, how many people in the dataset does this actually apply to?\n",
    "# 01/24/24 removed abortion, subtract by one most indices\n",
    "# 02/12/24 remove stillbirth and infer. stillbirth gets 0 reward, and infer is too hard\n",
    "task_commands = [\n",
    "    # 1) Take tail of one feature distribution\n",
    "    Task(\n",
    "        \"Focus slightly on the most elderly by age distribution.\",\n",
    "        lambda feature, state: state + SLIGHTLY_MODIFIER * feature[12 - 1],\n",
    "        lambda feature, state: state**2 + SLIGHTLY_MODIFIER * feature[12 - 1],\n",
    "    ),\n",
    "    Task(\n",
    "        \"The lowest income_bracket distribution tail is very important, focus heavily on the top 12.5%.\",\n",
    "        lambda feature, state: state + HEAVILY_MODIFIER * feature[37 - 1],\n",
    "        lambda feature, state: state**2 + HEAVILY_MODIFIER * feature[37 - 1],\n",
    "    ),\n",
    "    Task(\n",
    "        \"Select solely those who speak Hindi to analyze how this would affect the calls made to our beneficiaries.\",\n",
    "        lambda feature, state: state * if_(feature[13 - 1]),\n",
    "        lambda feature, state: state**2 * if_(feature[13 - 1]),\n",
    "    ),\n",
    "    Task(\n",
    "        \"Priortize slightly those who have had prior pregnancies.\",  # g feature\n",
    "        lambda feature, state: state + SLIGHTLY_MODIFIER * if_(feature[2]),\n",
    "        lambda feature, state: state**2 + SLIGHTLY_MODIFIER * if_(feature[2]),\n",
    "    ),\n",
    "    Task(\n",
    "        \"Heavily weight those who have had low education.\",  # education_1\n",
    "        lambda feature, state: state + HEAVILY_MODIFIER * if_(feature[17 - 1]),\n",
    "        lambda feature, state: state**2 + HEAVILY_MODIFIER * if_(feature[17 - 1]),\n",
    "    ),\n",
    "    # \" 2) Take lower and upper bound of one feature distribution\",\n",
    "    Task(\n",
    "        \"Focus only on both the young and elderly.\",  # education_1\n",
    "        lambda feature, state: state * if_(feature[12 - 1] or feature[8 - 1]),\n",
    "        lambda feature, state: state**2 * if_(feature[12 - 1] or feature[8 - 1]),\n",
    "    ),\n",
    "    Task(\n",
    "        \"Prefer slightly on the income_bracket bounds for the middle 40% of the population.\",  # income_bracker 3, 4, 5\n",
    "        lambda feature, state: state\n",
    "        + SLIGHTLY_MODIFIER\n",
    "        * if_(feature[39 - 1] or feature[40 - 1] or feature[41 - 1]),\n",
    "        lambda feature, state: state**2\n",
    "        + SLIGHTLY_MODIFIER\n",
    "        * if_(feature[39 - 1] or feature[40 - 1] or feature[41 - 1]),\n",
    "    ),\n",
    "    Task(\n",
    "        \"Slightly favor those women who do not own their own phone\",\n",
    "        lambda feature, state: state\n",
    "        + SLIGHTLY_MODIFIER * if_(feature[25 - 1] or feature[26 - 1]),\n",
    "        lambda feature, state: state**2\n",
    "        + SLIGHTLY_MODIFIER * if_(feature[25 - 1] or feature[26 - 1]),\n",
    "    ),\n",
    "    # \"Establish the lower and upper bounds of 'enrollment_gestation_age' for the central 80% of the data.\",\n",
    "    # \"Set the thresholds for the 'l' feature to identify the common range of live births.\",\n",
    "    # \" 3) Combine two feature distributions\",\n",
    "    Task(\n",
    "        \"Combine the distributions of 'age' and 'education' to heavily give precedence to low income impoverished youth.\",\n",
    "        lambda feature, state: state\n",
    "        + SLIGHTLY_MODIFIER * if_(feature[8 - 1] and feature[17 - 1]),\n",
    "        lambda feature, state: state**2\n",
    "        + SLIGHTLY_MODIFIER * if_(feature[8 - 1] and feature[17 - 1]),\n",
    "    ),\n",
    "    Task(\n",
    "        \"Focus slightly on the joint distribution of 'income_bracket' and 'phone_owner' for those with high financial status but with no phone ownership.\",\n",
    "        lambda feature, state: state\n",
    "        + SLIGHTLY_MODIFIER\n",
    "        * if_(\n",
    "            (feature[40 - 1] or feature[41 - 1])\n",
    "            and (feature[25 - 1] or feature[26 - 1])\n",
    "        ),\n",
    "        lambda feature, state: state**2\n",
    "        + SLIGHTLY_MODIFIER\n",
    "        * if_(\n",
    "            (feature[40 - 1] or feature[41 - 1])\n",
    "            and (feature[25 - 1] or feature[26 - 1])\n",
    "        ),\n",
    "    ),\n",
    "    Task(\n",
    "        \"Advantage slightly those who prefer being called after 7PM 'slot' registered at an NGO.\",\n",
    "        lambda feature, state: state\n",
    "        + SLIGHTLY_MODIFIER * if_(feature[32 - 1] and feature[33 - 1]),\n",
    "        lambda feature, state: state**2\n",
    "        + SLIGHTLY_MODIFIER * if_(feature[32 - 1] and feature[33 - 1]),\n",
    "    ),\n",
    "    Task(\n",
    "        \"Integrate the distributions of 'g' (gravidity) and 'l' (live) to concentrate heavily on mothers who have several pregnancies but not much success with birth\",\n",
    "        lambda feature, state: state\n",
    "        + HEAVILY_MODIFIER * if_(feature[2] > 1 and feature[5] == 0),\n",
    "        lambda feature, state: state**2\n",
    "        + HEAVILY_MODIFIER * if_(feature[2] > 1 and feature[5] == 0),\n",
    "    ),\n",
    "    Task(\n",
    "        \"Slightly fixate on those Marathi-speakers with middle-aged folks.\",\n",
    "        lambda feature, state: state\n",
    "        + SLIGHTLY_MODIFIER\n",
    "        * if_(feature[14 - 1] and (feature[10 - 1] or feature[11 - 1])),\n",
    "        lambda feature, state: state**2\n",
    "        + SLIGHTLY_MODIFIER\n",
    "        * if_(feature[14 - 1] and (feature[10 - 1] or feature[11 - 1])),\n",
    "    ),\n",
    "    # \" 4) Use latent label that requires inference (previously impoverished, now impoverished, most at risk)\",\n",
    "    # Task(\n",
    "    #     \"Infer disempowered mothers with little opportunity and focus heavily on them.\",  # mothers with low education, low income, and no phone ownership\n",
    "    #     lambda feature, state: state\n",
    "    #     + HEAVILY_MODIFIER\n",
    "    #     * if_(\n",
    "    #         feature[14-1]\n",
    "    #         and (feature[25-1] or feature[26-1])\n",
    "    #         and (feature[37-1] or feature[38-1]),\n",
    "    #         lambda feature, state: state**2\n",
    "    #         + SLIGHTLY_MODIFIER * if_(feature[14-1] and (feature[25-1] or feature[26-1])),\n",
    "    #     ),\n",
    "    #     lambda feature, state: state**2\n",
    "    #     + HEAVILY_MODIFIER\n",
    "    #     * if_(\n",
    "    #         feature[14-1]\n",
    "    #         and (feature[25-1] or feature[26-1])\n",
    "    #         and (feature[37-1] or feature[38-1]),\n",
    "    #         lambda feature, state: state**2\n",
    "    #         + SLIGHTLY_MODIFIER * if_(feature[14-1] and (feature[25-1] or feature[26-1])),\n",
    "    #     ),\n",
    "    # ),\n",
    "    # Task(\n",
    "    #     \"Identify 'most at risk' mothers by selecting those with a history of 's' (stillbirths) and have had little education and prefer them solely.\",\n",
    "    #     lambda feature, state: state * if_(feature[4] and (feature[17-1] or feature[18-1])),\n",
    "    #     lambda feature, state: (state**2)\n",
    "    #     * if_(feature[4] and (feature[17-1] or feature[18-1])),\n",
    "    # ),\n",
    "    Task(\n",
    "        \"Give slightly more attention for beneficiaries who likely work early in the morning and late at night.\",\n",
    "        lambda feature, state: state\n",
    "        + SLIGHTLY_MODIFIER * if_(feature[27 - 1] or feature[29 - 1]),\n",
    "        lambda feature, state: (state**2)\n",
    "        + SLIGHTLY_MODIFIER * if_(feature[27 - 1] or feature[29 - 1]),\n",
    "    ),\n",
    "    Task(\n",
    "        \"Apply inference rules to 'age' and 'p' to identify mothers at high risk due to age and number of past pregnancies and focus heavily on them.\",\n",
    "        lambda feature, state: state\n",
    "        + HEAVILY_MODIFIER * if_((feature[11 - 1] or feature[12 - 1]) and feature[3]),\n",
    "        lambda feature, state: (state**2)\n",
    "        + HEAVILY_MODIFIER * if_((feature[11 - 1] or feature[12 - 1]) and feature[3]),\n",
    "    ),\n",
    "    Task(\n",
    "        \"Infer technical challenges in reaching the phone that could indicate 'at-risk' beneficiaries and give preference slightly.\",  # this just means phone ownership or potentially low income, but requires inference.\n",
    "        lambda feature, state: state\n",
    "        + SLIGHTLY_MODIFIER * if_((feature[25 - 1] or feature[26 - 1]))\n",
    "        and feature[3],\n",
    "        lambda feature, state: (state**2)\n",
    "        + SLIGHTLY_MODIFIER * if_((feature[25 - 1] or feature[26 - 1]))\n",
    "        + SLIGHTLY_MODIFIER\n",
    "        * 0.2\n",
    "        * if_((feature[37 - 1] or feature[38 - 1])),  # slight weighting for low income\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "# TODO: state**2 == state since state \\in {0, 1}? potential answer: squaring the full output of the reward for shaped reward\n",
    "# now we wrap the shap\n",
    "def shaped_wrapper(reward_fun: RewardFun) -> RewardFun:\n",
    "    def shaped_reward(feature: npt.NDArray, state: int) -> float:\n",
    "        return reward_fun(feature, state) ** 2\n",
    "\n",
    "    return shaped_reward\n",
    "\n",
    "\n",
    "TASKS = []\n",
    "for command in task_commands:\n",
    "    command.human = shaped_wrapper(command.human)\n",
    "    TASKS.append(command)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def get_user_defined_attrs(cls) -> list:\n",
    "    return [\n",
    "        attr\n",
    "        for attr in dir(cls)\n",
    "        if not callable(getattr(cls, attr)) and not attr.startswith(\"__\")\n",
    "    ]\n",
    "\n",
    "\n",
    "class BaseHyperParameters:\n",
    "    @classmethod\n",
    "    def get_product(cls):\n",
    "        return list(\n",
    "            product(*[getattr(cls, attr) for attr in get_user_defined_attrs(cls)])\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class HyperParameters(BaseHyperParameters):\n",
    "    # alphabetical\n",
    "    _1_llm_reward = [True, False]\n",
    "    _2_arm_budget = [(48, 16), (21, 7)]\n",
    "    # _2_arm_budget = [(48, 16)]\n",
    "    _3_cot = [True, False]\n",
    "    _4_seeds = [12, 13, 42]\n",
    "    _5_task_indices = range(len(TASKS))\n",
    "    _6_zero_shot = [True, False]\n",
    "\n",
    "\n",
    "og_hparams = HyperParameters.get_product()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class HyperParameters:\n",
    "    # alphabetical\n",
    "    _1_llm_reward: str\n",
    "    _2_arm_budget: int\n",
    "    _3_cot: bool\n",
    "    _4_seeds: int\n",
    "    _5_task_indices: int\n",
    "    # _6_zero_shot: bool    \n",
    "    _stage: int\n",
    "    _iteration: int\n",
    "\n",
    "\n",
    "def get_vars(key):\n",
    "    try:\n",
    "        _, time, _, cot, seed, _, task, stage, iteration, _, reward_type, arms, budget, optin = key.split('_')\n",
    "    except ValueError as e:\n",
    "        # print(key.split('_'))\n",
    "        raise e\n",
    "    cot = eval(cot[3:])\n",
    "    budget = int(budget[1:])\n",
    "    arms = int(arms[1:])\n",
    "    seed = int(seed[4:])\n",
    "    stage = int(stage.split('=')[1])\n",
    "    task = int(task.split('=')[1])\n",
    "    iteration = int(iteration.split('=')[1].split('//')[0])\n",
    "\n",
    "    return HyperParameters(reward_type, arms, cot, seed, task, stage, iteration)\n",
    "\n",
    "\n",
    "hparams = [get_vars(k) for k in keys]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1149"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(192 * 4 + 192 + 192)\n",
    "len(hparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 48 budget results\n",
    "from collections import defaultdict\n",
    "res = defaultdict(list)\n",
    "for hparam, key in zip(hparams, keys):\n",
    "    if hparam._2_arm_budget == 48:\n",
    "        res[f\"nocall_{hparam._5_task_indices}\"].append(\n",
    "            results[key][\"No Calls\"][\"val\"]\n",
    "        )\n",
    "        res[f\"random_{hparam._5_task_indices}\"].append(results[key][\"RandomDS\"]['val'])        \n",
    "        ret = results[key]['PreFeRMAB']\n",
    "        k = f\"{hparam._1_llm_reward[3:]}_{hparam._5_task_indices}\"\n",
    "        # if k == 'REWbase_9':\n",
    "            # print(hparam)\n",
    "        if hparam._1_llm_reward != \"REWllm\":        \n",
    "            res[k].append(ret['val'])\n",
    "            continue\n",
    "        \n",
    "        # ignore zero shot for now\n",
    "        if hparam._stage == 0 and hparam._iteration == 0:\n",
    "            res['zeroshot_'+k].append(ret['val'])\n",
    "        if hparam._stage == 1 and hparam._iteration == 1:\n",
    "            if hparam._3_cot:\n",
    "                res['COT_'+k].append(ret['val'])\n",
    "            else:\n",
    "                res[k].append(ret['val'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nocall_0 139.07 4.62\n",
      "random_0 155.8 3.7\n",
      "base_0 170.21 12.66\n",
      "human_0 162.16 17.56\n",
      "llm_0 181.91 16.54\n",
      "zeroshot_llm_0 176.34 11.81\n",
      "COT_llm_0 167.55 24.77\n",
      "\n",
      "nocall_1 205.76 9.54\n",
      "random_1 222.63 9.28\n",
      "base_1 237.47 11.7\n",
      "human_1 245.63 19.44\n",
      "llm_1 218.81 17.04\n",
      "zeroshot_llm_1 245.22 12.1\n",
      "COT_llm_1 241.57 13.76\n",
      "\n",
      "nocall_2 70.54 5.33\n",
      "random_2 78.8 5.69\n",
      "base_2 85.75 11.89\n",
      "human_2 86.61 7.44\n",
      "llm_2 99.06 4.14\n",
      "zeroshot_llm_2 95.18 10.92\n",
      "COT_llm_2 81.98 12.5\n",
      "\n",
      "nocall_3 329.82 3.37\n",
      "random_3 346.67 2.5\n",
      "base_3 354.08 17.73\n",
      "human_3 354.09 14.61\n",
      "llm_3 358.27 18.69\n",
      "zeroshot_llm_3 356.72 15.28\n",
      "COT_llm_3 346.2 8.07\n",
      "\n",
      "nocall_4 151.44 5.28\n",
      "random_4 168.32 5.86\n",
      "base_4 178.31 13.06\n",
      "human_4 180.27 16.34\n",
      "llm_4 183.62 4.21\n",
      "zeroshot_llm_4 184.46 14.12\n",
      "COT_llm_4 181.28 9.49\n",
      "\n",
      "nocall_5 19.44 2.19\n",
      "random_5 21.82 2.58\n",
      "base_5 23.55 3.2\n",
      "human_5 24.57 2.11\n",
      "llm_5 23.26 3.89\n",
      "zeroshot_llm_5 23.72 4.1\n",
      "COT_llm_5 22.45 2.88\n",
      "\n",
      "nocall_6 211.88 10.21\n",
      "random_6 228.8 9.98\n",
      "base_6 231.61 6.12\n",
      "human_6 245.25 12.62\n",
      "llm_6 232.67 11.92\n",
      "zeroshot_llm_6 260.2 17.43\n",
      "COT_llm_6 238.39 23.16\n",
      "\n",
      "nocall_7 166.32 7.29\n",
      "random_7 183.25 6.84\n",
      "base_7 191.86 21.96\n",
      "human_7 189.24 17.01\n",
      "llm_7 210.87 8.82\n",
      "zeroshot_llm_7 199.93 27.49\n",
      "COT_llm_7 202.43 21.37\n",
      "\n",
      "nocall_8 137.7 2.55\n",
      "random_8 154.55 2.12\n",
      "base_8 162.92 15.22\n",
      "human_8 161.4 16.06\n",
      "llm_8 177.4 15.71\n",
      "zeroshot_llm_8 172.28 16.7\n",
      "COT_llm_8 172.8 18.13\n",
      "\n",
      "nocall_9 136.31 3.26\n",
      "random_9 153.12 2.29\n",
      "base_9 154.99 10.41\n",
      "human_9 156.58 11.17\n",
      "llm_9 175.44 8.47\n",
      "zeroshot_llm_9 183.24 13.22\n",
      "COT_llm_9 174.62 6.89\n",
      "\n",
      "nocall_10 161.94 6.33\n",
      "random_10 178.61 7.09\n",
      "base_10 191.51 24.64\n",
      "human_10 188.33 17.29\n",
      "llm_10 195.19 4.49\n",
      "zeroshot_llm_10 199.79 21.12\n",
      "COT_llm_10 176.95 17.24\n",
      "\n",
      "nocall_11 144.51 11.17\n",
      "random_11 161.34 11.09\n",
      "base_11 181.14 17.83\n",
      "human_11 171.05 8.41\n",
      "llm_11 187.76 19.24\n",
      "zeroshot_llm_11 165.88 13.26\n",
      "COT_llm_11 178.76 9.02\n",
      "\n",
      "nocall_12 171.21 5.46\n",
      "random_12 188.09 5.75\n",
      "base_12 197.67 10.93\n",
      "human_12 193.9 18.23\n",
      "llm_12 206.19 18.05\n",
      "zeroshot_llm_12 203.74 13.17\n",
      "COT_llm_12 203.49 26.03\n",
      "\n",
      "nocall_13 243.22 6.8\n",
      "random_13 260.04 6.14\n",
      "base_13 273.45 19.13\n",
      "human_13 269.78 12.04\n",
      "llm_13 278.47 24.02\n",
      "zeroshot_llm_13 286.98 24.8\n",
      "COT_llm_13 283.01 17.29\n",
      "\n",
      "nocall_14 152.75 10.42\n",
      "random_14 169.49 9.76\n",
      "base_14 184.01 27.02\n",
      "human_14 179.76 21.52\n",
      "llm_14 186.92 5.76\n",
      "zeroshot_llm_14 187.55 13.41\n",
      "COT_llm_14 190.41 17.6\n",
      "\n",
      "nocall_15 128.97 11.33\n",
      "random_15 136.54 11.45\n",
      "base_15 139.99 20.87\n",
      "human_15 136.96 10.64\n",
      "llm_15 148.57 13.14\n",
      "zeroshot_llm_15 146.99 14.56\n",
      "COT_llm_15 148.44 13.53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "results_matrix = [[] for i in range(16)]\n",
    "std_matrix = [[] for i in range(16)]\n",
    "for i in range(16):\n",
    "    for rew in ['nocall', 'random', 'base', 'human', 'llm', 'zeroshot_llm', 'COT_llm']:\n",
    "        k = f\"{rew}_{i}\"\n",
    "        print(k, round(np.mean(res[k]), 2), round(np.std(res[k]), 2))\n",
    "        results_matrix[i].append(np.mean(res[k]))\n",
    "        std_matrix[i].append(np.std(res[k]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[160.7 175.5 184.9 184.1 191.5 193.  188.1]\n",
      " [  6.6   6.4  15.3  13.9  12.1  15.2  15.1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=1)\n",
    "mu, std = np.array(results_matrix).mean(axis=0), np.array(std_matrix).mean(axis=0)\n",
    "print(np.vstack((mu, std)))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
